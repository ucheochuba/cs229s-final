{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('gemma_pytorch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose variant and machine type\n",
    "VARIANT = '2b-it' #@param ['2b', '2b-it', '9b', '9b-it', '27b', '27b-it']\n",
    "MACHINE_TYPE = 'cpu' #@param ['cuda', 'cpu']\n",
    "\n",
    "CONFIG = VARIANT[:2]\n",
    "if CONFIG == '2b':\n",
    "  CONFIG = '2b-v2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/uochuba/anaconda3/envs/cs229s/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "from datasets import load_dataset\n",
    "from evaluate import load  # Use evaluate instead of load_metric\n",
    "from gemma.model import GemmaForCausalLM\n",
    "from gemma.tokenizer import Tokenizer\n",
    "from gemma.config import get_model_config\n",
    "import kagglehub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded weights to: /Users/uochuba/.cache/kagglehub/models/google/gemma-2/pyTorch/gemma-2-2b-it/1\n"
     ]
    }
   ],
   "source": [
    "# Download weights directory from Kaggle\n",
    "try:\n",
    "    weights_dir = kagglehub.model_download(f'google/gemma-2/pyTorch/gemma-2-{VARIANT}')\n",
    "    print(f\"Downloaded weights to: {weights_dir}\")\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Failed to download model weights: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: The \"installation\" is just cloning the repo.\n",
    "# !git clone https://github.com/google/gemma_pytorch.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer and checkpoint files verified.\n"
     ]
    }
   ],
   "source": [
    "# Verify the presence of tokenizer and checkpoint files\n",
    "tokenizer_path = os.path.join(weights_dir, 'tokenizer.model')\n",
    "if not os.path.isfile(tokenizer_path):\n",
    "    raise FileNotFoundError(f\"Tokenizer not found at: {tokenizer_path}\")\n",
    "\n",
    "ckpt_path = os.path.join(weights_dir, 'model.ckpt')\n",
    "if not os.path.isfile(ckpt_path):\n",
    "    raise FileNotFoundError(f\"PyTorch checkpoint not found at: {ckpt_path}\")\n",
    "\n",
    "print(\"Tokenizer and checkpoint files verified.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GemmaForCausalLM(\n",
       "  (embedder): Embedding()\n",
       "  (model): GemmaModel(\n",
       "    (layers): ModuleList(\n",
       "      (0-25): 26 x Gemma2DecoderLayer(\n",
       "        (self_attn): GemmaAttention(\n",
       "          (qkv_proj): Linear()\n",
       "          (o_proj): Linear()\n",
       "        )\n",
       "        (mlp): GemmaMLP(\n",
       "          (gate_proj): Linear()\n",
       "          (up_proj): Linear()\n",
       "          (down_proj): Linear()\n",
       "        )\n",
       "        (input_layernorm): RMSNorm()\n",
       "        (post_attention_layernorm): RMSNorm()\n",
       "        (pre_feedforward_layernorm): RMSNorm()\n",
       "        (post_feedforward_layernorm): RMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): RMSNorm()\n",
       "  )\n",
       "  (sampler): Sampler()\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load SQuAD dataset\n",
    "dataset = load_dataset(\"squad\")\n",
    "\n",
    "dataset = dataset.shuffle(seed=42)\n",
    "\n",
    "# Load Gemma 2B model\n",
    "MODEL_VARIANT = \"2b-v2\"  # Update if needed\n",
    "model_config = get_model_config(MODEL_VARIANT)\n",
    "model_config.tokenizer = tokenizer_path\n",
    "model_config.quant = 'quant' in VARIANT\n",
    "\n",
    "# Load tokenizer and model\n",
    "# tokenizer = Tokenizer(tokenizer_path)\n",
    "torch.set_default_dtype(model_config.get_dtype())\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = GemmaForCausalLM(model_config)\n",
    "model.load_weights(ckpt_path)\n",
    "model.to(device).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def format_prompt(context, question):\n",
    "    \"\"\"\n",
    "    Format input for the Gemma model based on the updated tokenizer integration.\n",
    "    \"\"\"\n",
    "    prompt = f\"<start_of_turn>user\\nAnswer as concisely as possible. Context: {context}\\nQuestion: {question}<end_of_turn><eos>\\n<start_of_turn>model\\n\"\n",
    "    return prompt\n",
    "\n",
    "def generate_answer(model, prompt, max_length=128, device=\"cuda\"):\n",
    "    \"\"\"\n",
    "    Generate an answer using the Gemma model with integrated tokenizer.\n",
    "    \"\"\"\n",
    "    # Pass the prompt directly as a string\n",
    "    outputs = model.generate(prompt, output_len=max_length, device=device)  \n",
    "    answer = outputs.split(\"<end_of_turn>\")[0].split(\"<start_of_turn>model\\n\")[-1]\n",
    "    return answer.strip()\n",
    "\n",
    "def evaluate_squad(model, dataset, device=\"cuda\", num_examples=None, split=\"train\"):\n",
    "    \"\"\"\n",
    "    Evaluate Gemma on SQuAD using Exact Match (EM) and F1 metrics.\n",
    "    \"\"\"\n",
    "    metric = load(\"squad\")\n",
    "    exact_match = 0\n",
    "    f1 = 0\n",
    "    total = len(dataset[split])\n",
    "    if num_examples:\n",
    "        total = len(dataset[split].select(range(num_examples)))\n",
    "    else:\n",
    "        num_examples = total\n",
    "    \n",
    "    predictions = []\n",
    "    references = []\n",
    "\n",
    "    examples = dataset[split]\n",
    "    if num_examples:\n",
    "        examples = dataset[split].select(range(num_examples))\n",
    "    \n",
    "    for i, example in enumerate(examples):\n",
    "        context = example[\"context\"]\n",
    "        question = example[\"question\"]\n",
    "        answers = example[\"answers\"][\"text\"]\n",
    "        \n",
    "        # Generate model's answer\n",
    "        prompt = format_prompt(context, question)\n",
    "        prediction = generate_answer(model, prompt, max_length=128, device=device)\n",
    "        \n",
    "        # print(\"Context:\", context)\n",
    "        # print(\"Question:\", question)\n",
    "        # print(\"Expected Answers:\", answers)\n",
    "        # print(\"Model Prediction:\", prediction)\n",
    "        print(f\"Finished example {i} of {num_examples}\")\n",
    "        \n",
    "        # Prepare predictions and references in the format expected by the metric\n",
    "        predictions.append({\n",
    "            \"prediction_text\": prediction,\n",
    "            \"id\": str(len(predictions))  # Add a unique ID\n",
    "        })\n",
    "        \n",
    "        references.append({\n",
    "            \"answers\": {\n",
    "                \"text\": answers,\n",
    "                \"answer_start\": [0] * len(answers)  # Provide a default answer_start\n",
    "            },\n",
    "            \"id\": str(len(references))  # Add a unique ID\n",
    "        })\n",
    "    \n",
    "    # Compute metrics\n",
    "    scores = metric.compute(predictions=predictions, references=references)\n",
    "    \n",
    "    # Calculate average scores\n",
    "    exact_match = scores[\"exact_match\"]\n",
    "    f1 = scores[\"f1\"]\n",
    "    \n",
    "    print(f\"Exact Match (EM): {exact_match:.2f}%\")\n",
    "    print(f\"F1 Score: {f1:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished example 0 of 100\n",
      "Finished example 1 of 100\n",
      "Finished example 2 of 100\n",
      "Finished example 3 of 100\n",
      "Finished example 4 of 100\n",
      "Finished example 5 of 100\n",
      "Finished example 6 of 100\n",
      "Finished example 7 of 100\n",
      "Finished example 8 of 100\n",
      "Finished example 9 of 100\n",
      "Finished example 10 of 100\n",
      "Finished example 11 of 100\n",
      "Finished example 12 of 100\n",
      "Finished example 13 of 100\n",
      "Finished example 14 of 100\n",
      "Finished example 15 of 100\n",
      "Finished example 16 of 100\n",
      "Finished example 17 of 100\n",
      "Finished example 18 of 100\n",
      "Finished example 19 of 100\n",
      "Finished example 20 of 100\n",
      "Finished example 21 of 100\n",
      "Finished example 22 of 100\n",
      "Finished example 23 of 100\n",
      "Finished example 24 of 100\n",
      "Finished example 25 of 100\n",
      "Finished example 26 of 100\n",
      "Finished example 27 of 100\n",
      "Finished example 28 of 100\n",
      "Finished example 29 of 100\n",
      "Finished example 30 of 100\n",
      "Finished example 31 of 100\n",
      "Finished example 32 of 100\n",
      "Finished example 33 of 100\n",
      "Finished example 34 of 100\n",
      "Finished example 35 of 100\n",
      "Finished example 36 of 100\n",
      "Finished example 37 of 100\n",
      "Finished example 38 of 100\n",
      "Finished example 39 of 100\n",
      "Finished example 40 of 100\n",
      "Finished example 41 of 100\n",
      "Finished example 42 of 100\n",
      "Finished example 43 of 100\n",
      "Finished example 44 of 100\n",
      "Finished example 45 of 100\n",
      "Finished example 46 of 100\n",
      "Finished example 47 of 100\n",
      "Finished example 48 of 100\n",
      "Finished example 49 of 100\n",
      "Finished example 50 of 100\n",
      "Finished example 51 of 100\n",
      "Finished example 52 of 100\n",
      "Finished example 53 of 100\n",
      "Finished example 54 of 100\n",
      "Finished example 55 of 100\n",
      "Finished example 56 of 100\n",
      "Finished example 57 of 100\n",
      "Finished example 58 of 100\n",
      "Finished example 59 of 100\n",
      "Finished example 60 of 100\n",
      "Finished example 61 of 100\n",
      "Finished example 62 of 100\n",
      "Finished example 63 of 100\n",
      "Finished example 64 of 100\n",
      "Finished example 65 of 100\n",
      "Finished example 66 of 100\n",
      "Finished example 67 of 100\n",
      "Finished example 68 of 100\n",
      "Finished example 69 of 100\n",
      "Finished example 70 of 100\n",
      "Finished example 71 of 100\n",
      "Finished example 72 of 100\n",
      "Finished example 73 of 100\n",
      "Finished example 74 of 100\n",
      "Finished example 75 of 100\n",
      "Finished example 76 of 100\n",
      "Finished example 77 of 100\n",
      "Finished example 78 of 100\n",
      "Finished example 79 of 100\n",
      "Finished example 80 of 100\n",
      "Finished example 81 of 100\n",
      "Finished example 82 of 100\n",
      "Finished example 83 of 100\n",
      "Finished example 84 of 100\n",
      "Finished example 85 of 100\n",
      "Finished example 86 of 100\n",
      "Finished example 87 of 100\n",
      "Finished example 88 of 100\n",
      "Finished example 89 of 100\n",
      "Finished example 90 of 100\n",
      "Finished example 91 of 100\n",
      "Finished example 92 of 100\n",
      "Finished example 93 of 100\n",
      "Finished example 94 of 100\n",
      "Finished example 95 of 100\n",
      "Finished example 96 of 100\n",
      "Finished example 97 of 100\n",
      "Finished example 98 of 100\n",
      "Finished example 99 of 100\n",
      "Exact Match (EM): 42.00%\n",
      "F1 Score: 68.69%\n",
      "Saving layer scores...\n",
      "saved scores_by_layer/layer_0_scores.pt\n",
      "saved scores_by_layer/layer_1_scores.pt\n",
      "saved scores_by_layer/layer_2_scores.pt\n",
      "saved scores_by_layer/layer_3_scores.pt\n",
      "saved scores_by_layer/layer_4_scores.pt\n",
      "saved scores_by_layer/layer_5_scores.pt\n",
      "saved scores_by_layer/layer_6_scores.pt\n",
      "saved scores_by_layer/layer_7_scores.pt\n",
      "saved scores_by_layer/layer_8_scores.pt\n",
      "saved scores_by_layer/layer_9_scores.pt\n",
      "saved scores_by_layer/layer_10_scores.pt\n",
      "saved scores_by_layer/layer_11_scores.pt\n",
      "saved scores_by_layer/layer_12_scores.pt\n",
      "saved scores_by_layer/layer_13_scores.pt\n",
      "saved scores_by_layer/layer_14_scores.pt\n",
      "saved scores_by_layer/layer_15_scores.pt\n",
      "saved scores_by_layer/layer_16_scores.pt\n",
      "saved scores_by_layer/layer_17_scores.pt\n",
      "saved scores_by_layer/layer_18_scores.pt\n",
      "saved scores_by_layer/layer_19_scores.pt\n",
      "saved scores_by_layer/layer_20_scores.pt\n",
      "saved scores_by_layer/layer_21_scores.pt\n",
      "saved scores_by_layer/layer_22_scores.pt\n",
      "saved scores_by_layer/layer_23_scores.pt\n",
      "saved scores_by_layer/layer_24_scores.pt\n",
      "saved scores_by_layer/layer_25_scores.pt\n",
      "Layer scores saved.\n"
     ]
    }
   ],
   "source": [
    "# Run evaluation\n",
    "evaluate_squad(model, dataset, device=device, num_examples=100, split=\"train\")\n",
    "model.save_scores()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs229s",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
